{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"MLSpring2021 - HW2-1.ipynb","provenance":[{"file_id":"https://github.com/ga642381/ML2021-Spring/blob/main/HW02/HW02-1.ipynb","timestamp":1615616927499}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OYlaRwNu7ojq"},"source":["# **Homework 2-1 Phoneme Classification**"]},{"cell_type":"markdown","metadata":{"id":"emUd7uS7crTz"},"source":["## The DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus (TIMIT)\n","The TIMIT corpus of reading speech has been designed to provide speech data for the acquisition of acoustic-phonetic knowledge and for the development and evaluation of automatic speech recognition systems.\n","\n","This homework is a multiclass classification task, \n","we are going to train a deep neural network classifier to predict the phonemes for each frame from the speech corpus TIMIT.\n","\n","link: https://academictorrents.com/details/34e2b78745138186976cbc27939b1b34d18bd5b3"]},{"cell_type":"markdown","metadata":{"id":"KVUGfWTo7_Oj"},"source":["## Download Data\n","Download data from google drive, then unzip it.\n","\n","You should have `timit_11/train_11.npy`, `timit_11/train_label_11.npy`, and `timit_11/test_11.npy` after running this block.<br><br>\n","`timit_11/`\n","- `train_11.npy`: training data<br>\n","- `train_label_11.npy`: training label<br>\n","- `test_11.npy`:  testing data<br><br>\n","\n","**notes: if the google drive link is dead, you can download the data directly from Kaggle and upload it to the workspace**\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"OzkiMEcC3Foq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616896564766,"user_tz":-480,"elapsed":136676,"user":{"displayName":"Huang Vincent","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpl69ExtckeK66-37ql1MDxCxxGOFRsSBWZDbjBQ=s64","userId":"16668226139279532247"}},"outputId":"07388c7a-4032-4102-fdf3-6ad6eb8e1f3b"},"source":["!gdown --id '1-1ZbJqJqdmbswltY0AuZpvdhcNEGvGae' --output data.zip\n","!unzip data.zip\n","!ls "],"execution_count":1,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1-1ZbJqJqdmbswltY0AuZpvdhcNEGvGae\n","To: /content/data.zip\n","372MB [00:03, 101MB/s] \n","Archive:  data.zip\n","   creating: timit_11/\n","  inflating: timit_11/train_11.npy   \n","  inflating: timit_11/test_11.npy    \n","  inflating: timit_11/train_label_11.npy  \n","data.zip  sample_data  timit_11\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_L_4anls8Drv"},"source":["## Preparing Data\n","Load the training and testing data from the `.npy` file (NumPy array)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IJjLT8em-y9G","executionInfo":{"status":"ok","timestamp":1616896708541,"user_tz":-480,"elapsed":280376,"user":{"displayName":"Huang Vincent","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpl69ExtckeK66-37ql1MDxCxxGOFRsSBWZDbjBQ=s64","userId":"16668226139279532247"}},"outputId":"c3ca84b4-7bc8-4a1b-9825-c3d943f875c5"},"source":["import numpy as np\n","\n","print('Loading data ...')\n","\n","data_root='./timit_11/'\n","train = np.load(data_root + 'train_11.npy')\n","train_label = np.load(data_root + 'train_label_11.npy')\n","test = np.load(data_root + 'test_11.npy')\n","\n","print('Size of training data: {}'.format(train.shape))\n","print('Size of testing data: {}'.format(test.shape))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Loading data ...\n","Size of training data: (1229932, 429)\n","Size of testing data: (451552, 429)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"us5XW_x6udZQ"},"source":["## Create Dataset"]},{"cell_type":"code","metadata":{"id":"Fjf5EcmJtf4e","executionInfo":{"status":"ok","timestamp":1616896712044,"user_tz":-480,"elapsed":283873,"user":{"displayName":"Huang Vincent","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpl69ExtckeK66-37ql1MDxCxxGOFRsSBWZDbjBQ=s64","userId":"16668226139279532247"}}},"source":["import torch\n","from torch.utils.data import Dataset\n","\n","class TIMITDataset(Dataset):\n","    def __init__(self, X, y=None):\n","        self.data = torch.from_numpy(X).float()\n","        if y is not None:\n","            y = y.astype(np.int)\n","            self.label = torch.LongTensor(y)\n","        else:\n","            self.label = None\n","\n","    def __getitem__(self, idx):\n","        if self.label is not None:\n","            return self.data[idx], self.label[idx]\n","        else:\n","            return self.data[idx]\n","\n","    def __len__(self):\n","        return len(self.data)\n"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"otIC6WhGeh9v"},"source":["Split the labeled data into a training set and a validation set, you can modify the variable `VAL_RATIO` to change the ratio of validation data."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sYqi_lAuvC59","executionInfo":{"status":"ok","timestamp":1616896712046,"user_tz":-480,"elapsed":283856,"user":{"displayName":"Huang Vincent","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpl69ExtckeK66-37ql1MDxCxxGOFRsSBWZDbjBQ=s64","userId":"16668226139279532247"}},"outputId":"a32c3e93-394e-406c-92ec-d968180d1c2f"},"source":["VAL_RATIO = 0.1\n","\n","percent = int(train.shape[0] * (1 - VAL_RATIO))\n","train_x, train_y, val_x, val_y = train[:percent], train_label[:percent], train[percent:], train_label[percent:]\n","# train_x = train_x.reshape((train_x.shape[0],11,39))\n","# val_x = val_x.reshape((val_x.shape[0],11,39))\n","\n","print('Size of training set: {}'.format(train_x.shape))\n","print('Size of validation set: {}'.format(val_x.shape))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Size of training set: (1106938, 429)\n","Size of validation set: (122994, 429)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nbCfclUIgMTX"},"source":["Create a data loader from the dataset, feel free to tweak the variable `BATCH_SIZE` here."]},{"cell_type":"code","metadata":{"id":"RUCbQvqJurYc","executionInfo":{"status":"ok","timestamp":1616896713668,"user_tz":-480,"elapsed":285472,"user":{"displayName":"Huang Vincent","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpl69ExtckeK66-37ql1MDxCxxGOFRsSBWZDbjBQ=s64","userId":"16668226139279532247"}}},"source":["# BATCH_SIZE = 128\n","BATCH_SIZE = 64\n","\n","\n","from torch.utils.data import DataLoader\n","\n","train_set = TIMITDataset(train_x, train_y)\n","val_set = TIMITDataset(val_x, val_y)\n","train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) #only shuffle the training data\n","val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_SY7X0lUgb50"},"source":["Cleanup the unneeded variables to save memory.<br>\n","\n","**notes: if you need to use these variables later, then you may remove this block or clean up unneeded variables later<br>the data size is quite huge, so be aware of memory usage in colab**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y8rzkGraeYeN","executionInfo":{"status":"ok","timestamp":1616896713922,"user_tz":-480,"elapsed":285710,"user":{"displayName":"Huang Vincent","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpl69ExtckeK66-37ql1MDxCxxGOFRsSBWZDbjBQ=s64","userId":"16668226139279532247"}},"outputId":"301fda38-2342-4214-fdcd-dea91e89069b"},"source":["import gc\n","\n","del train, train_label, train_x, train_y, val_x, val_y\n","gc.collect()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["153"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"IRqKNvNZwe3V"},"source":["## Create Model"]},{"cell_type":"markdown","metadata":{"id":"FYr1ng5fh9pA"},"source":["Define model architecture, you are encouraged to change and experiment with the model architecture."]},{"cell_type":"code","metadata":{"id":"lbZrwT6Ny0XL","executionInfo":{"status":"ok","timestamp":1616900257527,"user_tz":-480,"elapsed":609,"user":{"displayName":"Huang Vincent","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpl69ExtckeK66-37ql1MDxCxxGOFRsSBWZDbjBQ=s64","userId":"16668226139279532247"}}},"source":["import torch\n","import torch.nn as nn\n","\n","\n","\n","class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","\n","        layer_input_size = 429 \n","\n","\n","        input_size = 39\n","        hidden_size = 256\n","        num_layers = 2\n","        num_classes = 39\n","        # bidirectional = True\n","        # self.num_directions = 2 if bidirectional else 1\n","        # layer_input_size = hidden_size * self.num_directions * 11 \n","\n","        # self.num_layers = num_layers\n","        # self.hidden_size = hidden_size\n","        # self.gru = nn.GRU(input_size, hidden_size, num_layers, bidirectional=bidirectional, dropout=0.2, batch_first=True)\n","        # self.lstm = nn.LSTM(input_size, hidden_size, num_layers, bidirectional=bidirectional, dropout=0.2, batch_first=True)\n","        # self.bn_fn0  = nn.BatchNorm1d(layer_input_size)\n","        # self.layer0 = nn.Linear(layer_input_size, 128)\n","        # self.layer00 = nn.Linear(128, num_classes)\n","\n","\n","        self.layer1 = nn.Linear(layer_input_size, 1024)\n","        self.layer2 = nn.Linear(1024, 512)\n","        self.layer3 = nn.Linear(512, 128)\n","        self.layer4 = nn.Linear(128, 256)\n","        self.layer5 = nn.Linear(256, 64)\n","        self.layer6 = nn.Linear(64, num_classes)\n","\n","        self.act_fn = nn.RReLU() \n","        self.act_fn2 = nn.Sigmoid()\n","\n","        self.bn_fn1  = nn.BatchNorm1d(1024)\n","        self.bn_fn2  = nn.BatchNorm1d(512)\n","        self.bn_fn3  = nn.BatchNorm1d(128)\n","        self.bn_fn4  = nn.BatchNorm1d(256)\n","        self.bn_fn5  = nn.BatchNorm1d(64)\n","\n","        # self.dropout = nn.Dropout(0.4)\n","        self.dropout = nn.Dropout(0.2)\n","\n","\n","    def forward(self, x):\n","\n","        # h_0 = torch.zeros(self.num_layers*self.num_directions, x.size(0), self.hidden_size).to(device) \n","        # c_0 = torch.zeros(self.num_layers*self.num_directions, x.size(0), self.hidden_size).to(device) \n","        # hx = (h_0, c_0)\n","        # x, hx = self.lstm(x,hx)\n","\n","        # hx = h_0\n","        # x, hx = self.gru(x,hx)\n","        # x = x[:,-1,:]\n","        # x = x[:,-2:,:] # batch_size,len\n","        # x = x.reshape(x.size(0),-1)\n","        # x = self.bn_fn0(x)\n","        # x = self.layer0(x)\n","        # x = self.act_fn(x)\n","        # x = self.dropout0(x) \n","        # x = self.layer00(x) \n","        # x = self.act_fn(x)\n","\n","        \n","        x = self.layer1(x)\n","        x = self.bn_fn1(x)\n","        x = self.act_fn(x)\n","        x = self.dropout(x) \n","\n","        x = self.layer2(x)\n","        # x = self.bn_fn2(x)\n","        x = self.act_fn(x)\n","        x = self.dropout(x)\n","\n","        x = self.layer3(x)\n","        x = self.bn_fn3(x)\n","        x = self.act_fn(x)\n","        x = self.dropout(x) \n","\n","        x = self.layer4(x)\n","        # x = self.bn_fn4(x)\n","        x = self.act_fn(x)\n","        x = self.dropout(x) \n","\n","        x = self.layer5(x)\n","        # x = self.bn_fn5(x)\n","        x = self.act_fn(x)\n","        x = self.dropout(x)\n","\n","        x = self.layer6(x)\n","        x = self.act_fn(x)\n","\n","        return x"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VRYciXZvPbYh"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"y114Vmm3Ja6o","executionInfo":{"status":"ok","timestamp":1616900257802,"user_tz":-480,"elapsed":863,"user":{"displayName":"Huang Vincent","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpl69ExtckeK66-37ql1MDxCxxGOFRsSBWZDbjBQ=s64","userId":"16668226139279532247"}}},"source":["#check device\n","def get_device():\n","  return 'cuda' if torch.cuda.is_available() else 'cpu'"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sEX-yjHjhGuH"},"source":["Fix random seeds for reproducibility."]},{"cell_type":"code","metadata":{"id":"88xPiUnm0tAd","executionInfo":{"status":"ok","timestamp":1616900257805,"user_tz":-480,"elapsed":854,"user":{"displayName":"Huang Vincent","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpl69ExtckeK66-37ql1MDxCxxGOFRsSBWZDbjBQ=s64","userId":"16668226139279532247"}}},"source":["# fix random seed\n","def same_seeds(seed):\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)  \n","    np.random.seed(seed)  \n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KbBcBXkSp6RA"},"source":["Feel free to change the training parameters here."]},{"cell_type":"code","metadata":{"id":"QTp3ZXg1yO9Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616900883521,"user_tz":-480,"elapsed":403,"user":{"displayName":"Huang Vincent","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghpl69ExtckeK66-37ql1MDxCxxGOFRsSBWZDbjBQ=s64","userId":"16668226139279532247"}},"outputId":"0aa0c248-95f2-44be-fe97-d84c6d1e4151"},"source":["# fix random seed for reproducibility\n","same_seeds(5)\n","\n","# get device \n","device = get_device()\n","print(f'DEVICE: {device}')\n","\n","# training parameters\n","num_epoch = 1000               # number of training epoch\n","learning_rate = 0.001       # learning rate\n","# the path where checkpoint saved\n","model_path = './model.ckpt'\n","\n","# create model, define a loss function, and optimizer\n","model = Classifier().to(device)\n","criterion = nn.CrossEntropyLoss() \n","# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.5, weight_decay=0.00001 )\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["DEVICE: cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CdMWsBs7zzNs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"938d7d30-a92a-4b5f-e56e-521e92e8b75b"},"source":["# start training\n","\n","best_acc = 0.0\n","\n","scheduler1 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n","\n","# scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=0.1,patience=10)\n","\n","early_stop_cnt = 0\n","\n","for epoch in range(num_epoch):\n","\n","    \n","    train_acc = 0.0\n","    train_loss = 0.0\n","    val_acc = 0.0\n","    val_loss = 0.0\n","\n","    # training\n","    model.train() # set the model to training mode\n","    for i, data in enumerate(train_loader):\n","        inputs, labels = data\n","        \n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad() \n","        outputs = model(inputs) \n","        batch_loss = criterion(outputs, labels)\n","        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n","        batch_loss.backward() \n","        optimizer.step()\n","\n","        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n","        train_loss += batch_loss.item()\n","\n","    # validation\n","    if len(val_set) > 0:\n","        model.eval() # set the model to evaluation mode\n","        with torch.no_grad():\n","            for i, data in enumerate(val_loader):\n","                inputs, labels = data\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                outputs = model(inputs)\n","                batch_loss = criterion(outputs, labels) \n","                _, val_pred = torch.max(outputs, 1) \n","            \n","                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n","                val_loss += batch_loss.item()\n","\n","            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n","                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n","            ))\n","            # scheduler1.step(val_loss) \n","            # if the model improves, save a checkpoint at this epoch\n","            if val_acc > best_acc:\n","                best_acc = val_acc\n","                torch.save(model.state_dict(), model_path)\n","                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n","                early_stop_cnt = 0\n","            else:\n","              early_stop_cnt += 1\n","            # if early_stop_cnt > 10:\n","            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n","              # break\n","            # threshold = 0.8\n","            # if train_acc/len(train_set) > train_loss/len(train_loader) + threshold :\n","            #   print('Train{:3.6f}>Val{:3.6f}'.format(train_acc/len(train_set), val_acc/len(val_set)))\n","            #   break\n","    else:\n","        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n","            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n","        ))\n","        # if train_acc/len(train_set)>train_loss/len(train_loader)+0.1:\n","        #   break\n","\n","# if not validating, save the last epoch\n","if len(val_set) == 0:\n","    torch.save(model.state_dict(), model_path)\n","    print('saving model at last epoch')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[001/1000] Train Acc: 0.554488 Loss: 1.474710 | Val Acc: 0.655739 loss: 1.100121\n","saving model with acc 0.656\n","[002/1000] Train Acc: 0.611016 Loss: 1.267118 | Val Acc: 0.677098 loss: 1.019084\n","saving model with acc 0.677\n","[003/1000] Train Acc: 0.628136 Loss: 1.205187 | Val Acc: 0.691310 loss: 0.967216\n","saving model with acc 0.691\n","[004/1000] Train Acc: 0.638646 Loss: 1.169168 | Val Acc: 0.698424 loss: 0.939928\n","saving model with acc 0.698\n","[005/1000] Train Acc: 0.645061 Loss: 1.143405 | Val Acc: 0.702238 loss: 0.924723\n","saving model with acc 0.702\n","[006/1000] Train Acc: 0.650973 Loss: 1.123965 | Val Acc: 0.707457 loss: 0.906181\n","saving model with acc 0.707\n","[007/1000] Train Acc: 0.654649 Loss: 1.109060 | Val Acc: 0.709173 loss: 0.898092\n","saving model with acc 0.709\n","[008/1000] Train Acc: 0.658327 Loss: 1.097790 | Val Acc: 0.711888 loss: 0.888607\n","saving model with acc 0.712\n","[009/1000] Train Acc: 0.660560 Loss: 1.088302 | Val Acc: 0.714051 loss: 0.883875\n","saving model with acc 0.714\n","[010/1000] Train Acc: 0.663403 Loss: 1.079865 | Val Acc: 0.715490 loss: 0.880805\n","saving model with acc 0.715\n","[011/1000] Train Acc: 0.664741 Loss: 1.073584 | Val Acc: 0.715067 loss: 0.875102\n","[012/1000] Train Acc: 0.667026 Loss: 1.066675 | Val Acc: 0.720084 loss: 0.860181\n","saving model with acc 0.720\n","[013/1000] Train Acc: 0.667470 Loss: 1.061384 | Val Acc: 0.721425 loss: 0.860348\n","saving model with acc 0.721\n","[014/1000] Train Acc: 0.669769 Loss: 1.055914 | Val Acc: 0.719807 loss: 0.862412\n","[015/1000] Train Acc: 0.670681 Loss: 1.051910 | Val Acc: 0.724686 loss: 0.847586\n","saving model with acc 0.725\n","[016/1000] Train Acc: 0.672260 Loss: 1.047018 | Val Acc: 0.725881 loss: 0.837992\n","saving model with acc 0.726\n","[017/1000] Train Acc: 0.673421 Loss: 1.042856 | Val Acc: 0.726775 loss: 0.841277\n","saving model with acc 0.727\n","[018/1000] Train Acc: 0.674636 Loss: 1.038016 | Val Acc: 0.724442 loss: 0.840043\n","[019/1000] Train Acc: 0.674772 Loss: 1.036448 | Val Acc: 0.728572 loss: 0.833170\n","saving model with acc 0.729\n","[020/1000] Train Acc: 0.675860 Loss: 1.032822 | Val Acc: 0.725913 loss: 0.838936\n","[021/1000] Train Acc: 0.677790 Loss: 1.028839 | Val Acc: 0.729255 loss: 0.826524\n","saving model with acc 0.729\n","[022/1000] Train Acc: 0.677958 Loss: 1.026582 | Val Acc: 0.728832 loss: 0.831694\n","[023/1000] Train Acc: 0.678297 Loss: 1.024659 | Val Acc: 0.727556 loss: 0.829090\n","[024/1000] Train Acc: 0.679393 Loss: 1.021956 | Val Acc: 0.732605 loss: 0.819975\n","saving model with acc 0.733\n","[025/1000] Train Acc: 0.679847 Loss: 1.019477 | Val Acc: 0.730995 loss: 0.826499\n","[026/1000] Train Acc: 0.680256 Loss: 1.016891 | Val Acc: 0.730060 loss: 0.826446\n","[027/1000] Train Acc: 0.681081 Loss: 1.014751 | Val Acc: 0.731271 loss: 0.822569\n","[028/1000] Train Acc: 0.682080 Loss: 1.012355 | Val Acc: 0.732849 loss: 0.819323\n","saving model with acc 0.733\n","[029/1000] Train Acc: 0.682475 Loss: 1.010905 | Val Acc: 0.731784 loss: 0.819667\n","[030/1000] Train Acc: 0.682080 Loss: 1.009993 | Val Acc: 0.732353 loss: 0.817125\n","[031/1000] Train Acc: 0.683252 Loss: 1.008607 | Val Acc: 0.732995 loss: 0.818091\n","saving model with acc 0.733\n","[032/1000] Train Acc: 0.683670 Loss: 1.005735 | Val Acc: 0.733654 loss: 0.812822\n","saving model with acc 0.734\n","[033/1000] Train Acc: 0.684600 Loss: 1.003821 | Val Acc: 0.735003 loss: 0.809711\n","saving model with acc 0.735\n","[034/1000] Train Acc: 0.684576 Loss: 1.003332 | Val Acc: 0.735109 loss: 0.810233\n","saving model with acc 0.735\n","[035/1000] Train Acc: 0.684862 Loss: 1.001256 | Val Acc: 0.732198 loss: 0.818194\n","[036/1000] Train Acc: 0.685730 Loss: 0.999148 | Val Acc: 0.735255 loss: 0.810582\n","saving model with acc 0.735\n","[037/1000] Train Acc: 0.686103 Loss: 0.996841 | Val Acc: 0.735776 loss: 0.806323\n","saving model with acc 0.736\n","[038/1000] Train Acc: 0.686155 Loss: 0.996500 | Val Acc: 0.734906 loss: 0.810384\n","[039/1000] Train Acc: 0.686674 Loss: 0.994778 | Val Acc: 0.733914 loss: 0.810396\n","[040/1000] Train Acc: 0.687471 Loss: 0.994485 | Val Acc: 0.737499 loss: 0.803003\n","saving model with acc 0.737\n","[041/1000] Train Acc: 0.687169 Loss: 0.993283 | Val Acc: 0.736768 loss: 0.804273\n","[042/1000] Train Acc: 0.687977 Loss: 0.991713 | Val Acc: 0.738085 loss: 0.804639\n","saving model with acc 0.738\n","[043/1000] Train Acc: 0.688787 Loss: 0.989733 | Val Acc: 0.738101 loss: 0.798834\n","saving model with acc 0.738\n","[044/1000] Train Acc: 0.688271 Loss: 0.990333 | Val Acc: 0.736150 loss: 0.802492\n","[045/1000] Train Acc: 0.688895 Loss: 0.988950 | Val Acc: 0.735873 loss: 0.808236\n","[046/1000] Train Acc: 0.688871 Loss: 0.986873 | Val Acc: 0.739947 loss: 0.795202\n","saving model with acc 0.740\n","[047/1000] Train Acc: 0.689526 Loss: 0.986080 | Val Acc: 0.739191 loss: 0.796377\n","[048/1000] Train Acc: 0.689660 Loss: 0.985901 | Val Acc: 0.738930 loss: 0.796852\n","[049/1000] Train Acc: 0.689606 Loss: 0.984881 | Val Acc: 0.738150 loss: 0.795610\n","[050/1000] Train Acc: 0.690404 Loss: 0.982755 | Val Acc: 0.738564 loss: 0.800711\n","[051/1000] Train Acc: 0.690110 Loss: 0.982041 | Val Acc: 0.737800 loss: 0.799404\n","[052/1000] Train Acc: 0.690902 Loss: 0.981838 | Val Acc: 0.739987 loss: 0.791773\n","saving model with acc 0.740\n","[053/1000] Train Acc: 0.690704 Loss: 0.980539 | Val Acc: 0.741028 loss: 0.792884\n","saving model with acc 0.741\n","[054/1000] Train Acc: 0.691200 Loss: 0.978820 | Val Acc: 0.740166 loss: 0.792803\n","[055/1000] Train Acc: 0.691144 Loss: 0.979415 | Val Acc: 0.739012 loss: 0.792626\n","[056/1000] Train Acc: 0.691191 Loss: 0.978986 | Val Acc: 0.740898 loss: 0.789559\n","[057/1000] Train Acc: 0.692141 Loss: 0.977651 | Val Acc: 0.739971 loss: 0.790932\n","[058/1000] Train Acc: 0.691966 Loss: 0.976586 | Val Acc: 0.741508 loss: 0.790858\n","saving model with acc 0.742\n","[059/1000] Train Acc: 0.692261 Loss: 0.976969 | Val Acc: 0.740394 loss: 0.792102\n","[060/1000] Train Acc: 0.692431 Loss: 0.975865 | Val Acc: 0.737524 loss: 0.793439\n","[061/1000] Train Acc: 0.693208 Loss: 0.974410 | Val Acc: 0.741142 loss: 0.787478\n","[062/1000] Train Acc: 0.693042 Loss: 0.973704 | Val Acc: 0.741012 loss: 0.790528\n","[063/1000] Train Acc: 0.693406 Loss: 0.972730 | Val Acc: 0.740272 loss: 0.793622\n","[064/1000] Train Acc: 0.692840 Loss: 0.973501 | Val Acc: 0.740565 loss: 0.790521\n","[065/1000] Train Acc: 0.693594 Loss: 0.972015 | Val Acc: 0.739386 loss: 0.794601\n","[066/1000] Train Acc: 0.693488 Loss: 0.972078 | Val Acc: 0.740256 loss: 0.791750\n","[067/1000] Train Acc: 0.693738 Loss: 0.970895 | Val Acc: 0.741109 loss: 0.787428\n","[068/1000] Train Acc: 0.693609 Loss: 0.969903 | Val Acc: 0.742288 loss: 0.787334\n","saving model with acc 0.742\n","[069/1000] Train Acc: 0.693749 Loss: 0.968809 | Val Acc: 0.742752 loss: 0.785388\n","saving model with acc 0.743\n","[070/1000] Train Acc: 0.694315 Loss: 0.968414 | Val Acc: 0.741882 loss: 0.786566\n","[071/1000] Train Acc: 0.694360 Loss: 0.968965 | Val Acc: 0.741182 loss: 0.786467\n","[072/1000] Train Acc: 0.695099 Loss: 0.966316 | Val Acc: 0.743004 loss: 0.782446\n","saving model with acc 0.743\n","[073/1000] Train Acc: 0.694800 Loss: 0.968167 | Val Acc: 0.742361 loss: 0.787677\n","[074/1000] Train Acc: 0.694820 Loss: 0.967167 | Val Acc: 0.741800 loss: 0.783672\n","[075/1000] Train Acc: 0.694846 Loss: 0.966894 | Val Acc: 0.742979 loss: 0.786161\n","[076/1000] Train Acc: 0.695322 Loss: 0.966219 | Val Acc: 0.740695 loss: 0.788171\n","[077/1000] Train Acc: 0.695196 Loss: 0.965105 | Val Acc: 0.744719 loss: 0.780435\n","saving model with acc 0.745\n","[078/1000] Train Acc: 0.695595 Loss: 0.964115 | Val Acc: 0.743329 loss: 0.782311\n","[079/1000] Train Acc: 0.695638 Loss: 0.963712 | Val Acc: 0.741776 loss: 0.786812\n","[080/1000] Train Acc: 0.695844 Loss: 0.963027 | Val Acc: 0.742687 loss: 0.783541\n","[081/1000] Train Acc: 0.696173 Loss: 0.962936 | Val Acc: 0.744004 loss: 0.781709\n","[082/1000] Train Acc: 0.695832 Loss: 0.962917 | Val Acc: 0.745459 loss: 0.782282\n","saving model with acc 0.745\n","[083/1000] Train Acc: 0.696001 Loss: 0.962911 | Val Acc: 0.745988 loss: 0.775835\n","saving model with acc 0.746\n","[084/1000] Train Acc: 0.696208 Loss: 0.961826 | Val Acc: 0.742288 loss: 0.779883\n","[085/1000] Train Acc: 0.696165 Loss: 0.962114 | Val Acc: 0.744069 loss: 0.780698\n","[086/1000] Train Acc: 0.696801 Loss: 0.960882 | Val Acc: 0.743044 loss: 0.777350\n","[087/1000] Train Acc: 0.697022 Loss: 0.959871 | Val Acc: 0.744760 loss: 0.777902\n","[088/1000] Train Acc: 0.697227 Loss: 0.959889 | Val Acc: 0.743760 loss: 0.780493\n","[089/1000] Train Acc: 0.696605 Loss: 0.959379 | Val Acc: 0.741703 loss: 0.786194\n","[090/1000] Train Acc: 0.697381 Loss: 0.959220 | Val Acc: 0.743744 loss: 0.778759\n","[091/1000] Train Acc: 0.697054 Loss: 0.958757 | Val Acc: 0.743305 loss: 0.780089\n","[092/1000] Train Acc: 0.697055 Loss: 0.958981 | Val Acc: 0.744923 loss: 0.774879\n","[093/1000] Train Acc: 0.697240 Loss: 0.957096 | Val Acc: 0.744573 loss: 0.784463\n","[094/1000] Train Acc: 0.697747 Loss: 0.957897 | Val Acc: 0.744988 loss: 0.776955\n","[095/1000] Train Acc: 0.698162 Loss: 0.956383 | Val Acc: 0.741979 loss: 0.782653\n","[096/1000] Train Acc: 0.697311 Loss: 0.956505 | Val Acc: 0.740166 loss: 0.781561\n","[097/1000] Train Acc: 0.697655 Loss: 0.955762 | Val Acc: 0.745410 loss: 0.776282\n","[098/1000] Train Acc: 0.697536 Loss: 0.956616 | Val Acc: 0.743963 loss: 0.781214\n","[099/1000] Train Acc: 0.698067 Loss: 0.955921 | Val Acc: 0.744532 loss: 0.774211\n","[100/1000] Train Acc: 0.698661 Loss: 0.954073 | Val Acc: 0.744264 loss: 0.775063\n","[101/1000] Train Acc: 0.698086 Loss: 0.954021 | Val Acc: 0.744638 loss: 0.776971\n","[102/1000] Train Acc: 0.698026 Loss: 0.954423 | Val Acc: 0.745069 loss: 0.775930\n","[103/1000] Train Acc: 0.698484 Loss: 0.953357 | Val Acc: 0.745841 loss: 0.771193\n","[104/1000] Train Acc: 0.698812 Loss: 0.953202 | Val Acc: 0.744589 loss: 0.777560\n","[105/1000] Train Acc: 0.698838 Loss: 0.953096 | Val Acc: 0.744402 loss: 0.779122\n","[106/1000] Train Acc: 0.698703 Loss: 0.953258 | Val Acc: 0.744605 loss: 0.773703\n","[107/1000] Train Acc: 0.699054 Loss: 0.952018 | Val Acc: 0.746687 loss: 0.769998\n","saving model with acc 0.747\n","[108/1000] Train Acc: 0.699020 Loss: 0.951076 | Val Acc: 0.745418 loss: 0.772675\n","[109/1000] Train Acc: 0.699025 Loss: 0.952710 | Val Acc: 0.743727 loss: 0.782030\n","[110/1000] Train Acc: 0.699296 Loss: 0.950148 | Val Acc: 0.745004 loss: 0.778180\n","[111/1000] Train Acc: 0.698816 Loss: 0.951651 | Val Acc: 0.744874 loss: 0.775537\n","[112/1000] Train Acc: 0.699213 Loss: 0.951751 | Val Acc: 0.744288 loss: 0.780683\n","[113/1000] Train Acc: 0.699358 Loss: 0.950938 | Val Acc: 0.745134 loss: 0.775113\n","[114/1000] Train Acc: 0.699676 Loss: 0.949598 | Val Acc: 0.745906 loss: 0.772635\n","[115/1000] Train Acc: 0.699724 Loss: 0.949123 | Val Acc: 0.744768 loss: 0.773893\n","[116/1000] Train Acc: 0.699176 Loss: 0.949723 | Val Acc: 0.745906 loss: 0.770423\n","[117/1000] Train Acc: 0.699471 Loss: 0.949924 | Val Acc: 0.746996 loss: 0.770574\n","saving model with acc 0.747\n","[118/1000] Train Acc: 0.699292 Loss: 0.949394 | Val Acc: 0.747248 loss: 0.770974\n","saving model with acc 0.747\n","[119/1000] Train Acc: 0.699821 Loss: 0.949789 | Val Acc: 0.745849 loss: 0.770399\n","[120/1000] Train Acc: 0.700066 Loss: 0.949435 | Val Acc: 0.747484 loss: 0.768927\n","saving model with acc 0.747\n","[121/1000] Train Acc: 0.700682 Loss: 0.948499 | Val Acc: 0.748134 loss: 0.770392\n","saving model with acc 0.748\n","[122/1000] Train Acc: 0.700270 Loss: 0.948660 | Val Acc: 0.747614 loss: 0.771813\n","[123/1000] Train Acc: 0.699697 Loss: 0.948379 | Val Acc: 0.746427 loss: 0.767762\n","[124/1000] Train Acc: 0.700785 Loss: 0.947135 | Val Acc: 0.747297 loss: 0.767516\n","[125/1000] Train Acc: 0.700130 Loss: 0.947737 | Val Acc: 0.747036 loss: 0.770217\n","[126/1000] Train Acc: 0.700454 Loss: 0.947355 | Val Acc: 0.745971 loss: 0.773283\n","[127/1000] Train Acc: 0.700705 Loss: 0.945995 | Val Acc: 0.745101 loss: 0.771196\n","[128/1000] Train Acc: 0.700983 Loss: 0.946360 | Val Acc: 0.746061 loss: 0.770866\n","[129/1000] Train Acc: 0.700743 Loss: 0.946745 | Val Acc: 0.746931 loss: 0.771879\n","[130/1000] Train Acc: 0.700806 Loss: 0.945961 | Val Acc: 0.747248 loss: 0.773507\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1Hi7jTn3PX-m"},"source":["*斜體文字*## Testing"]},{"cell_type":"markdown","metadata":{"id":"NfUECMFCn5VG"},"source":["Create a testing dataset, and load model from the saved checkpoint."]},{"cell_type":"code","metadata":{"id":"1PKjtAScPWtr"},"source":["# create testing dataset\n","# test = test.reshape((test.shape[0],11,39))\n","test_set = TIMITDataset(test, None)\n","test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n","\n","# create model and load weights from checkpoint\n","model = Classifier().to(device)\n","model.load_state_dict(torch.load(model_path))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"940TtCCdoYd0"},"source":["Make prediction."]},{"cell_type":"code","metadata":{"id":"84HU5GGjPqR0"},"source":["predict = []\n","model.eval() # set the model to evaluation mode\n","with torch.no_grad():\n","    for i, data in enumerate(test_loader):\n","        inputs = data\n","        inputs = inputs.to(device)\n","        outputs = model(inputs)\n","        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n","\n","        for y in test_pred.cpu().numpy():\n","            predict.append(y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AWDf_C-omElb"},"source":["Write prediction to a CSV file.\n","\n","After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."]},{"cell_type":"code","metadata":{"id":"GuljYSPHcZir"},"source":["with open('prediction.csv', 'w') as f:\n","    f.write('Id,Class\\n')\n","    for i, y in enumerate(predict):\n","        f.write('{},{}\\n'.format(i, y))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m2GEULkgUM5c"},"source":["Reference\n","This code is completely written by NTUEE.\n","Copying or reusing this code is required to specify the original author.\n","\n","E.g.\n","Source: NTUEE (https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW02/HW02-1.ipynb)"]}]}